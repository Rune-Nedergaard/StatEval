fit <- glmnet(x, y, lambda = bestlamda, family = "multinomial",  type.multinomial = "grouped")
coef(fit.lasso.cv, s = "lambda.min")
fit <- glmnet(x, y, s = bestlamda, family = "multinomial",  type.multinomial = "grouped")
fit <- glmnet(x, y, s = "lambda.min", family = "multinomial",  type.multinomial = "grouped")
fit <- glmnet(x, y, s = bestlamda, family = "multinomial")
fit <- glmnet(x, y, s = bestlamda, family = "multinomial",type.measure = "class")
coef(fit.lasso.cv, s =0)
test <- coef(fit.lasso.cv, s = "lambda.min")
View(test)
test <- as.matrix(coef(fit.lasso.cv, s = "lambda.min"))
View(test)
fit <- glmnet(x, y, s = bestlamda, family = "multinomial",type.measure = "class")
newx <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex +xzVertex
+ xyMax + xyMin +yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +xStd +zStd + zMin + pathDist, data = val_data)
test <- predict(cvfit, newx = newx, s = "lambda.min", type = "class")
test <- predict(fit.lasso.cv, newx = newx, s = "lambda.min", type = "class")
test
plot(fit.lasso.cv, xvar='lambda')
coef(fit.lasso.cv, s = "lambda.min")
plot(fit.lasso.cv, xvar='lambda')
(fit.lasso.cv, s = "lambda.min")
regularizedpreds <- predict(fit.lasso.cv, newx = newx, s = "lambda.min", type = "class")
regularizedpreds
fit1 <- glmnet(x,
y,
alpha = 1,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
train_data
fit1 <- glmnet(as.matrix(train_data[,4:length(train_data)]),
y,
alpha = 1,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
fit1 <- glmnet(as.matrix(train_data[,4:length(train_data)]),
y,
alpha = 0,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
fit1
fit1 <- glmnet(x,
y,
alpha = 0,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
fit1
plot(fit1, xvar = "lambda")
abline(v = log(fit.lasso.cv$lambda.min), lty = 2)
fit.lasso.pred <- predict(fit.lasso.best, t)
plot(fit1, xvar = "lambda")
plot(fit1, xvar = "lambda")
View(fit1)
require(methods)
#x <- as.matrix(train_data[,4:]) # all X vars
x <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex +xzVertex
+ xyMax + xyMin +yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +xStd +zStd + zMin + pathDist, data = train_data)
y <- train_data$Experiment
#using 10-fold cross validation on training data to pick hyper parameters (lambda value)
fit.lasso.cv <- cv.glmnet(x, y,
alpha = 1, family = "multinomial", type.measure = "class")
plot(fit.lasso.cv, xvar='lambda', label=T)
fit1 <- glmnet(x,
y,
alpha = 1,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
rm("fit1")
fit1 <- glmnet(x,
y,
alpha = 1,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
fit1 <- glmnet(x,
y,
alpha = 1,
lambda = fit.lasso.cv$lambda.1se,
family = "multinomial")
coef(fit.lasso.cv, s = "lambda.min")
test <- coef(fit.lasso.cv, s = "lambda.min")
View(test)
coef(fit.lasso.cv, s = "lambda.min")[1]
# ======================================================
# Load data
# ======================================================
load("armdata.RData")
# number of experiments (first layer )
n_experiments <- length(armdata);n_experiments
# number of persons (second layer)
n_participants <- length(armdata[[1]]
);n_participants
# number of repetitions (third layer)
n_repetitions <- length(armdata[[1]][[1]]);n_repetitions
# dimensions of data matrix
dim_matrix <- dim(armdata[[1]][[1]][[1]]); dim_matrix
# Calculate total number of repetitions
print(sprintf("Total number of repitions: %d", n_repetitions*n_participants*n_experiments))
total_nan_rows <- rep(NA, n_experiments*n_participants*n_repetitions)
nan_locations <- c()
idx <- 1
# Loop through experiments
for (i in 1:n_experiments){
# Loop through participants
for (j in 1:length(armdata[[i]])){
# Loop through repetitions
for (k in 1:length(armdata[[i]][[j]])){
# print(sprintf("Experiment %d, participant %d, repetition %d",i, j, k))
# print(dim(armdata[[i]][[j]][[k]]))
# count rows with nan values
nan_rows <- sum(rowSums(is.na(armdata[[i]][[j]][[k]])) > 0)
nan_row_numbers <- which(rowSums(is.na(armdata[[i]][[j]][[k]])) > 0)
if(nan_rows > 0){
print(sprintf("Experiment %d, participant %d, repetition %d ([[%d]][[%d]][[%d]]):",i, j, k, i, j, k))
print(sprintf("%d rows with NaN:", nan_rows))
print(nan_row_numbers)
nan_locations <- c(nan_locations, list(c(i,j,k)))
}
total_nan_rows[idx] <- nan_rows
idx <- idx + 1
}
}
}
# Total number of rows with NaN values
print(sprintf("Total number of rows with NaN: %d",sum(total_nan_rows)))
# ----- Replace NaN values
nan_locations
# What to replace NaN values with
replace_with <- 0
nan_locations
# Loop through matrices with NaN values
for(i in 1:length(nan_locations)){
# Get matrix of coordinates
arm_matrix <- armdata[[nan_locations[[i]][[1]]]][[nan_locations[[i]][[2]]]][[nan_locations[[i]][[3]]]]
# print(arm_matrix)
# Loop through points in matrix
x_repl <- NA
y_repl <- NA
z_repl <- NA
for(j in nrow(arm_matrix):1){
if(is.na(sum(arm_matrix[j,])) ){
arm_matrix[j,1] <- x_repl
arm_matrix[j,2] <- y_repl
arm_matrix[j,3] <- z_repl
}
x_repl <- arm_matrix[j,1]
y_repl <- arm_matrix[j,2]
z_repl <- arm_matrix[j,3]
}
# print(arm_matrix)
# Replace with new matrix
armdata[[nan_locations[[i]][[1]]]][[nan_locations[[i]][[2]]]][[nan_locations[[i]][[3]]]] <- arm_matrix
}
# Save new data to file
saveRDS(armdata, file="armdata_cleaned.rds")
write.csv(armdata, "armdata.csv")
fit1 <- glmnet(x,
y,
alpha = 0,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
==========================================
# Create jpg file path for plots by providing a plot name
getJpgFilePath <- function(plot_name) {
plots_path <- "plots"
file_type <- "jpg"
path <- paste(paste(plots_path, plot_name, sep="/"), file_type, sep=".")
}
getDist3d <- function(v1, v2) {
dist <- sqrt((v2[1] - v1[1])^2 + (v2[2]- v1[2])^2 + (v2[3]- v1[3])^2)
return(dist)
}
# =======================================================
# Load/prepare data
# =======================================================
# Load cleaned data
armdata <- readRDS("armdata_cleaned.rds")
armdata[[1]][[1]]
# Define experiment setups
exp_setups <- data.frame(exp1 = c(15.0, 20),
exp2 = c(15.0, 27.5),
exp3 = c(15.0, 35),
exp4 = c(22.5, 20),
exp5 = c(22.5, 27.5),
exp6 = c(22.5, 35),
exp7 = c(30.0, 20),
exp8 = c(30.0, 27.5),
exp9 = c(30.0, 35),
exp10 = c(37.5, 20),
exp11 = c(47.5, 27.5),
exp12 = c(37.5, 35),
exp13 = c(45.0, 20),
exp14 = c(45.0, 27.5),
exp15 = c(45.0, 35),
exp16 = c(0,0)
)
# Set experiment setup names
row.names(exp_setups) <- c("d","obstacle_height")
# number of experiments (first layer )
n_experiments <- length(armdata);n_experiments
# number of persons (second layer)
n_participants <- length(armdata[[1]]
);n_participants
# number of repetitions (third layer)
n_repetitions <- length(armdata[[1]][[1]]);n_repetitions
# Matrix of path stats
paths <- c()
# Loop through experiments
for (i in 1:n_experiments){
# Loop through participants
for (j in 1:length(armdata[[i]])){
# Loop through repetitions
for (k in 1:length(armdata[[i]][[j]])){
# Define repetition
repetition <- armdata[[i]][[j]][[k]]
'
for (m in 1:ncol(repetition)){
for (n in 1:nrow(repetition)){
if (is.na(repetition[n,m])){
repetition[n,m] <- sum(repetition[n+1,m]+repetition[n-1,m])/2
}
}
}
'
# Define coordinates
x <- repetition[,1]
y <- repetition[,2]
z <- repetition[,3]
# Get x-value of highest point on path (vertex of path)
xz_vertex <- repetition[which.max(z), 1]
# Get z-value of highest point on path (vertex of path)
z_vertex <- repetition[which.max(z), 3]
# Get x-value where y is max
xy_max <- repetition[which.max(y),1]
# Get x-value where y is min
xy_min <- repetition[which.min(y),1]
# See how inefficient people move in y-axis
nulls <- rep(0,length(y))
#y_shakiness <- abs(nulls-y)
y_shakiness_mean <- mean(abs(nulls-y))
y_shakiness_std <- sd(abs(nulls-y))
yz_max <- repetition[which.max(z),2]
# par(mfrow = c(1,2))
# plot(x,y_shakiness)
# abline(v = xz_vertex)
# plot(x,z)
# abline(v = xz_vertex)
#
# Calculate y-value range
y_range <- abs(max(y) - min(y))
# y standard deviation
y_std <- sd(y)
#x standard deviation
x_std <- sd(x)
#z staandard deviation
z_std <- sd(z)
z_min <- min(repetition[,3])
# Calculate path height (diference between max and min height)
path_height <- max(z) - min(z)
# Define distance between object and
d <- exp_setups[[i]][[1]]
# Define obstacle height
obstacle_height <- exp_setups[[i]][[2]]
curve_dist <- 0
prev_point <- NA
# Loop through all points and sum distance between points
for (n in 1:nrow(repetition)){
if (!is.na(sum(prev_point))){
curve_dist <- curve_dist + getDist3d(repetition[n,], prev_point)
}
prev_point <- repetition[n,]
}
paths <- rbind(paths, c(i, d, obstacle_height, j, k, path_height, z_vertex, xz_vertex, xy_max, xy_min, y_shakiness_mean, y_shakiness_std, yz_max, y_range, y_std, x_std, z_std, z_min, curve_dist))
}
}
}
# Crate dataframe from matrix
paths <- data.frame(paths)
# Add column names
colnames(paths) <- c("Experiment", "d" , "obstacleHeight", "Person", "Repetition", "pathHeight", "zVertex", "xzVertex","xyMax","xyMin","yShakinessMean","yShakinessStd","yzMax", "yRange", "yStd","xStd","zStd", "zMin", "pathDist")
head(paths)
# Define variables as factors
paths$Experiment <- as.factor(paths$Experiment)
paths$Person <- as.factor(paths$Person)
paths$Repetition <- as.factor(paths$Repetition)
paths$d <- as.factor(paths$d)
paths$obstacleHeight <- as.factor(paths$obstacleHeight)
###########################################################
#                       MODELLING                         #
###########################################################
require(nnet)
library(modelr)
library(purrr)
library(dplyr)
library(ggplot2)
library(yardstick)
library(MASS)
################## STEP AIC ###################
smp_size <- floor(0.75 * nrow(paths))
set.seed(42)
train_idx <- sample(seq_len(nrow(paths)), size = smp_size)
train_data <- paths[train_idx, ]
val_data <- paths[-train_idx, ]
val_data_matrix <- data.matrix(val_data)
val_features <- val_data_matrix[,4:ncol(val_data_matrix)]
val_labels <- val_data_matrix[,1]
############# Lasso regression  ##############
library(glmnet)
require(methods)
#x <- as.matrix(train_data[,4:]) # all X vars
x <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex +xzVertex
+ xyMax + xyMin +yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +xStd +zStd + zMin + pathDist, data = train_data)
y <- train_data$Experiment
#using 10-fold cross validation on training data to pick hyper parameters (lambda value)
fit.lasso.cv <- cv.glmnet(x, y,
alpha = 0, family = "multinomial", type.measure = "class")
bestlamda <- fit.lasso.cv$lambda.1se
bestlamda
fit <- glmnet(x, y, s = bestlamda, family = "multinomial",type.measure = "class")
coef(fit.lasso.cv, s = "lambda.min")
plot(fit.lasso.cv, xvar='lambda', label=T)
newx <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex +xzVertex
+ xyMax + xyMin +yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +xStd +zStd + zMin + pathDist, data = val_data)
fit1 <- glmnet(x,
y,
alpha = 0,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
source("~/GitHub/StatEval/stepAIC.R", echo=TRUE)
fit.lasso.pred <- predict(fit.lasso.best, t)
fit1 <- glmnet(x,
y,
alpha = 0,
lambda = fit.lasso.cv$lambda.min,
family = "multinomial")
fit1
coef(fit1)
#using 10-fold cross validation on training data to pick hyper parameters (lambda value)
fit.lasso.cv <- cv.glmnet(x, y,
alpha = 1, family = "multinomial", type.measure = "class")
temp <- coef(fit.lasso.cv, s = fit.lasso.cv$lambda.min)
beta <- Reduce(cbind, temp)
beta <- beta[apply(beta != 0, 1, any),]
colnames(beta) <- names(temp)
beta
View(beta)
View(beta)
beta[1]
fit <- glmnet(x, y, family = "multinomial", type.multinomial = "grouped")
plot(fit, xvar = "lambda", label = TRUE, type.coef = "2norm")
fit <- glmnet(x, y, family = "multinomial", type.multinomial = "grouped")
fit
fit2 <- glmnet(x, y, family = "multinomial")
plot(fit2, xvar = "lambda", label = TRUE, type.coef = "2norm")
plot(fit2, xvar = "lambda", label = TRUE, type.coef = "coef")
plot(fit, xvar = "lambda", label = TRUE, type.coef = "coef")
View(fit)
coef(fit)
coef(fit)[1]
coef(fit)[[1]]
coef(fit, type.coef = "coef")
coef(fit, type.coef = "coef")[1]
save_coef <- coef(fit)
View(save_coef)
coef(fit)[1][1]
coef(fit)[1][1][1][1]
coef(fit)[[1]]
coef(fit)
fit2 <- glmnet(x, y, family = "multinomial")
plot(fit2, xvar = "lambda", label = TRUE, type.coef = "coef")
#Predicting on validation data using optimal lambda
xyz_predictions <- predict(fit.lasso.cv, newx = newx, s = "lambda.min", type = "class")
sum(xyz_predictions == val_labels)
mean(xyz_predictions == val_labels)
index_best <- which(fit.lasso.cv$lambda == fit.lasso.cv$lambda.min)
beta <- fit.lasso.cv$glmnet.fit$beta[, index_best]
index_best
beta <- fit.lasso.cv$glmnet.fit$beta
beta <- fit.lasso.cv$glmnet.fit$beta[, index_best]
beta
head(sort(beta, decreasing = TRUE), 20)
actual_class <- as.integer(val_data$Experiment)
tab_class <- table(actual_class, xyz_predictions)
tab_class
confusionMatrix(tab_class, mode = "everything")
install.packages("quanteda")
install.packages("caret")
require(caret)
confusionMatrix(tab_class, mode = "everything")
xyz_predictions
confusionMatrix(tab_class, mode = "everything")
table(xyz_predictions)
table(actual_class)
tab_class <- table(actual_class, as.factor(xyz_predictions))
require(caret)
confusionMatrix(tab_class, mode = "everything")
confusionMatrix(xyz_predictions, actual_class, mode = "everything")
confusionMatrix(xyz_predictions, actual_class)
length(actual_class)
length(xyz_predictions)
confusionMatrix(as.factor(xyz_predictions), actual_class)
confusionMatrix(as.int(xyz_predictions), actual_class)
confusionMatrix(as.int(xyz_predictions), actual_class)
confusionMatrix(as.integer(xyz_predictions), actual_class)
confusionMatrix(as.integer(xyz_predictions), actual_class)
predicted <- as.integer(xyz_predictions)
confusionMatrix(predicted, actual_class)
table(predicted)
table(actual_class)
confusionMatrix(table(predicted, actual_class))
confusionMatrix(table(predicted, actual_class), mode = "everything")
#Getting everything
caret::confusionMatrix(table(predicted, actual_class), mode = "everything")
######## Starting over with YZ coordinates ###########
#only including variables that do not contain info on x-axis
x <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex
+yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +zStd + zMin, data = train_data)
YZ.fit <- cv.glmnet(x, y,
alpha = 1, family = "multinomial", type.measure = "class")
predicted_xyz <- as.integer(xyz_predictions)
######## Predicting for YZ ###########
#formatting validation data
newx <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex
+yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +zStd + zMin , data = val_data)
#Predicting on validation data using optimal lambda
yz_predictions <- predict(fit.lasso.cv, newx = newx, s = "lambda.min", type = "class")
######## Predicting for YZ ###########
#formatting validation data
newx <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex
+yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +zStd + zMin , data = val_data)
#Predicting on validation data using optimal lambda
yz_predictions <- predict(fit.lasso.cv, newx = newx, s = "lambda.min", type = "class")
par(mfrow = c(4,4)
plot(fit2, xvar = "lambda", label = TRUE, type.coef = "coef")
par(mfrow = c(4,4))
plot(fit2, xvar = "lambda", label = TRUE, type.coef = "coef")
plot(XYZ_fit)
#using 10-fold cross validation on training data to pick hyper parameters (lambda value)
XYZ_fit <- cv.glmnet(x, y,
alpha = 1, family = "multinomial", type.measure = "class")
plot(XYZ_fit)
par(mfrow = c(1,1))
plot(XYZ_fit)
#x <- as.matrix(train_data[,4:]) # all X vars
x <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex +xzVertex
+ xyMax + xyMin +yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +xStd +zStd + zMin + pathDist, data = train_data)
y <- train_data$Experiment
#using 10-fold cross validation on training data to pick hyper parameters (lambda value)
XYZ_fit <- cv.glmnet(x, y,
alpha = 1, family = "multinomial", type.measure = "class")
plot(XYZ_fit)
#formatting validation data so it plays well with glmnet
newx <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex +xzVertex
+ xyMax + xyMin +yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +xStd +zStd + zMin + pathDist, data = val_data)
#Predicting on validation data using optimal lambda
xyz_predictions <- predict(XYZ_fit, newx = newx, s = "lambda.min", type = "class")
#accuracy
mean(xyz_predictions == val_labels) #62.25%
actual_class <- as.integer(val_data$Experiment)
predicted_xyz <- as.integer(xyz_predictions)
tab_class <- table(actual_class, xyz_predictions)
#Shows a lot of info
confusionMatrix(table(predicted, actual_class), mode = "everything")
XYZ_fit$lambda.min
#Predicting on validation data using optimal lambda
yz_predictions <- predict(YZ.fit, newx = newx, s = "lambda.min", type = "class")
######## Predicting for YZ ###########
#formatting validation data
newx <- model.matrix(Experiment ~ Person + Repetition +pathHeight+ zVertex
+yShakinessMean +yShakinessStd +yzMax +yRange +
yStd +zStd + zMin , data = val_data)
#Predicting on validation data using optimal lambda
yz_predictions <- predict(YZ.fit, newx = newx, s = "lambda.min", type = "class")
#accuracy
mean(yz_predictions == val_labels) #62.25%
actual_class <- as.integer(val_data$Experiment)
predicted_yz <- as.integer(yz_predictions)
tab_class <- table(actual_class, yz_predictions)
confusionMatrix(table(predicted, actual_class), mode = "everything")
#accuracy
mean(yz_predictions == val_labels) #62.25%
#accuracy
1-mean(yz_predictions == val_labels) #62.25%
actual_class <- as.integer(val_data$Experiment)
predicted_xyz <- as.integer(xyz_predictions)
tab_class <- table(actual_class, xyz_predictions)
#Shows a lot of info
confusionMatrix(table(predicted_xyz, actual_class), mode = "everything")
confusionMatrix(table(predicted_xyz, predicted_yz), mode = "everything")
correct_xyz <- predicted_xyz == actual_class
correct_xyz
correct_yz <- predicted_yz == actual_class
yz_correct_alone <- (correct_yz == TRUE & correct_xyz == FALSE)
yz_correct_alone
sum(yz_correct_alone)
table(correct_xyz,correct_yz)
mcnemar.test(table(correct_xyz,correct_yz))
sum(correct_yz)
sum(correct_xyz)
actual_class <- as.integer(val_data$Experiment)
predicted_yz <- as.integer(yz_predictions)
tab_class <- table(actual_class, yz_predictions)
confusionMatrix(table(predicted_yz, actual_class), mode = "everything")
mcnemar.test(table(correct_xyz,correct_yz))
confusionMatrix(table(correct_xyz,correct_yz), mode = "everything")
